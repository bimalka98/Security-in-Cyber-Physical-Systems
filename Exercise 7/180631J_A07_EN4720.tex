\documentclass[11pt,letterpaper]{article}

\usepackage[letterpaper,margin=0.8in,nohead]{geometry}

\usepackage[colorlinks]{hyperref}
\usepackage{url}
\usepackage{breakurl}

\hypersetup{
	colorlinks,
	linkcolor={red},
	citecolor={red},
	urlcolor={blue}
}

\usepackage{verbatim}
\usepackage{fancyvrb}
\usepackage{scrextend}
\usepackage{enumitem}
\usepackage{url}
\usepackage{tabularx}

\usepackage{caption}
\usepackage{graphicx}
\usepackage{subcaption}

\usepackage{changepage}   % for the adjustwidth environment

\newenvironment{answer}{\em \color{blue} \begin{adjustwidth}{1cm}{1cm}}{\end{adjustwidth}}

% math
\usepackage{amsthm,amsmath}
\usepackage{amsfonts}

\newcommand{\mc}[1]{\mathcal{#1}}	% Mechanisms / Algorithms
\newcommand{\rv}[1]{\mathbf{#1}}    % Random variable

\newcommand{\pr}[1]{\mathrm{Pr}\{#1\}} % Probability

\newtheorem{corollary}{\bf Corollary}%[theorem]
\newtheorem{lemma}{\bf Lemma}%[theorem]
\newtheorem{definition}{\bf Definition}%[section]

\newtheorem{observation}{\bf Observation}%[theorem]

% load cleveref last!
\usepackage[capitalise]{cleveref}
\usepackage{float}


\begin{document}
	
	\title{EN4720: Security in Cyber-Physical Systems \\ Exercise --- Privacy}
	
	%% This is an individual assignment!!
	%% TODO: put your name and index number here here!
\author{ \textcolor{blue}{Name: Thalagala B. P.} \\ \textcolor{blue}{Index No: 180631J}}
	
	\maketitle
	
	\begin{center}
		\color{red}\bf This is an individual exercise! \\ Due Date: 24 June 2023 by 11.59 PM
	\end{center}
	
	% \section*{Instructions}
	% %
	
	% For this assignment, you have to read the given questions carefully and provide answers in the given space.
	
	\section*{Section 1}
	
	Provide answers to questions 1 through 7 in the given space referring to the Tables~\ref{tab:SampleData} and~\ref{tab:SampleData2} given below.
	
	\begin{table}[h!]
		\caption{Example dataset on the weekly usage of taxis by certain individuals
		} \label{tab:SampleData}
		\begin{tabularx}{\columnwidth}{|p{2cm}|p{2cm}|p{3cm}|X|X|}
			\hline
			\textbf{Name} & \textbf{Age} & \textbf{Gender}  & \textbf{Occupation}  & \textbf{Average No. of taxi trips per week} \\
			\hline
			943145 & 21 & Female & Legal Counsel & 15\\\hline
			
			\hline
			416765 & 38 & Male & Data Privacy Officer & 2 \\\hline
			
			\hline
			356891 & 44 & Female & Database Administrator & 3 \\ \hline
			
			\hline
			723145 & 25 & Female & Administrative 
			Assistant & 1\\\hline
			
			\hline
			239976 & 31 & Male & Data Privacy Officer & 5 \\\hline
			
			\hline
			562396 & 42 & Female & Programmer & 3\\ \hline
			
			\hline
			964825 & 22 & Female & Administrative 
			Assistant & 4 \\ \hline
			
			\hline
			873892 & 30 & Female & Legal Counsel & 2\\ \hline
			
		\end{tabularx}
	\end{table}
	
	\begin{enumerate}
		
		\item What type of data anonymization technique is used for the dataset given in Table~\ref{tab:SampleData}? 
		
		\begin{answer}
			\textbf{De-identification}: actual names of the individuals have been replaced by a numerical identifier. Because, the attribute `Name' of a data record is a direct identifier which can be used to identify a given individual uniquely.
		\end{answer}
		
		\item Is this technique sufficient to protect the privacy of the associated individuals? If not, why?
		
		\begin{answer}
			No. Removing only the name can not guarantee the preservation of privacy, because it can be \textbf{susceptible to linkage attacks} which leads to re-identification of the individuals by linking the information with other external information (zip, sex, birth date).
		\end{answer}
		
		
		
		\item Briefly describe three other data anonymization techniques that can be used to anonymize data.
		
		\begin{answer}
			\begin{itemize}
				\item \textbf{Generalization}: Rather than including the specific information about an attribute (eg: age = 21) in a record, it can be replaced with more generalized value (eg: range of ages = (20 to 30)).
				
				\item \textbf{Suppression}: Some fields of the data base can be entirely removed, if that field contains highly unique identifiers such as national ID card numbers and telephone numbers of the individuals.
				
				\item \textbf{Data swapping}: some of the values of a given record can be swapped with some other record's value while keeping the statistical properties of the database intact.
			\end{itemize}
		\end{answer}
		
				
		\begin{table}[h!]  
			\caption{Modified example dataset on the weekly usage of taxis by certain individuals
			} \label{tab:SampleData2}
			
			\begin{tabularx}{\columnwidth}{|p{2cm}|X|X|X|}
				\hline
				\textbf{Age} & \textbf{Gender}  & \textbf{Occupation}  & \textbf{Average No. of taxi trips per week} \\
				\hline
				21 to 30 & Female & Legal Counsel & 15\\\hline
				
				\hline
				31 to 40 & Male & Data Privacy Officer & 2 \\\hline
				
				\hline
				41 to 50 & Female & IT & 3 \\ \hline
				
				\hline
				21 to 30 & Female & Administrative 
				Assistant & 1\\\hline
				
				\hline
				31 to 40 & Male & Data Privacy Officer & 5 \\\hline
				
				\hline
				41 to 50 & Female & IT & 3\\ \hline
				
				\hline
				21 to 30 & Female & Administrative 
				Assistant & 4 \\ \hline
				
				\hline
				21 to 30 & Female & Legal Counsel & 2\\ \hline
				
			\end{tabularx}
		\end{table}
		
		\item The example dataset given in Table~\ref{tab:SampleData} was modified to improve anonymity. The new dataset is provided in Table~\ref{tab:SampleData2}. Mention all the data anonymization techniques that were used to achieve this.
		
		\begin{answer}
			\begin{itemize}
				\item Generalization: ages have been replaced with ranges of ages, some value of the occupation filed hs been replaced with its parent set's value {\tt IT = \{Database Administrator, Programmer, ...\}}
				\item Suppression: Name field has been removed entirely
			\end{itemize}
		\end{answer}
		
		\item Can k-anonymity be observed in the data given in Table~\ref{tab:SampleData2}? If so, what is the value of k?
		
		\begin{answer}
			Yes. K = 2
		\end{answer}
		
		\item Is privacy guaranteed for the data given in Table~\ref{tab:SampleData2}? Justify your answer.
		
		\begin{answer}
			Although the above methods reduce the risk of re-identification, it is not possible to grantee the preservation of privacy of data. The database can be still \textbf{susceptible to attribute disclosure attacks}, if a given equivalence class (the group of $k$ records with the same quasi-identifiers) has the same value for the given sensitive attribute. Let's assume the sensitive attribute in the Table \ref{tab:SampleData2} is the \textit{Average No. of taxi trips per week}. Then if we consider the $3^{rd}$ and $6^{th}$ records in that table they have the same value for the sensitive attribute. 
		\end{answer}
		
		\pagebreak
		\item Calculate the risk of re-identification for data given in Table~\ref{tab:SampleData2} (mention as a percentage). Justify your answer.
		
		\begin{answer}
			Consider below tables with rearranged records for easy comparison bout the linkages between them. Let's define the risk of re-identification as the ratio between 
			
			\begin{table}[h!]
				\caption{Original dataset}
				\begin{tabularx}{\columnwidth}{|p{2cm}|p{2cm}|p{3cm}|X|X|}
					\hline
					\textbf{Name} & \textbf{Age} & \textbf{Gender}  & \textbf{Occupation}  & \textbf{Average No. of taxi trips per week} \\\hline
					943145 & 21 & Female & Legal Counsel & 15\\\hline
					873892 & 30 & Female & Legal Counsel & 2\\ \hline
					\hline
					416765 & 38 & Male & Data Privacy Officer & 2 \\\hline
					239976 & 31 & Male & Data Privacy Officer & 5 \\\hline
					\hline			
					356891 & 44 & Female & Database Administrator & 3 \\ \hline
					562396 & 42 & Female & Programmer & 3\\ \hline
					\hline									
					723145 & 25 & Female & Administrative 
					Assistant & 1\\\hline
					964825 & 22 & Female & Administrative 
					Assistant & 4 \\ \hline																																					
				\end{tabularx}
			\end{table}
			
			
			\begin{table}[H]  
				\caption{Rearranged example dataset}				
				\begin{tabularx}{\columnwidth}{|p{2cm}|p{2cm}|X|X|}
					\hline
					\textbf{Age} & \textbf{Gender}  & \textbf{Occupation}  & \textbf{Average No. of taxi trips per week} \\
					\hline
					21 to 30 & Female & Legal Counsel & 15\\\hline
					21 to 30 & Female & Legal Counsel & 2\\ \hline					
					\hline	
					31 to 40 & Male & Data Privacy Officer & 2 \\\hline
					31 to 40 & Male & Data Privacy Officer & 5 \\\hline					
					\hline
					41 to 50 & Female & IT & 3 \\ \hline
					41 to 50 & Female & IT & 3\\ \hline					
					\hline
					21 to 30 & Female & Administrative Assistant & 1\\\hline
					21 to 30 & Female & Administrative Assistant & 4 \\ \hline					
				\end{tabularx}
			\end{table} 					
		\end{answer}
		
		\item Suggest ways to enhance the privacy of this dataset considering l-diversity.
		
		\begin{answer}
			L-diversity ensures that withing each equivalence group (quasi-identifier group) there are at least $l$ distinct values for each attribute. This make it harder to learn the sensitive attribute through attribute disclosure attacks. In order to achieve l-diversity, generalization and suppression techniques has to be used on the original data set recursively until we get $l$ distinct values under a given attribute, within every quasi-identifier group.
		\end{answer}
		
	\end{enumerate}
	
	\section*{Section 2}
	\begin{enumerate}
		
		\item What is differential privacy?
		
		\begin{answer}
			Differential privacy ensures that the membership of a particular individual in a given database is not disclosed. That is, the data that can be inferred about an individual is roughly the same regardless of the fact that the data about that individual is actually available in the database or not. This functionality is achieved by adding a carefully calibrated noise to the output of the queries to the database.
		\end{answer}
		
		\item Briefly describe what is \textbf{protected} and \textbf{not protected} by applying differential privacy.
		
		\begin{answer}
			\begin{itemize}
				\item \textbf{\sc Protected}:
				\begin{itemize}
					\item \textbf{Membership privacy} of an individual (described above)
					
					\item \textbf{Ability to withstand linkage attacks}, by making no assumptions about the availability of auxiliary information. That is even an attacker has some auxiliary info about a given individual, he will not be able to re-identify the individual by using the outputs of the queries.					
				\end{itemize} 
				
				\item \textbf{\sc Not protected}:
				\begin{itemize}
					\item \textbf{Utility of the data} is destroyed if unnecessary amount of noise is added to the real data. This can make accurate decision making impossible. (eg: a particular application may provide \textit{false or less useful information} to the user depending on the data that the app accessed via a differential private protected database - location based suggestions)
					
					\item \textbf{Privacy of groups}: Even though an attacker is unable to infer accurate information about a given individual, the retrieved information can still be used to gain insights about the various groups/ teams inside a database.
				\end{itemize}
				
			\end{itemize}
		\end{answer}
		
		\item The following mechanism is used to satisfy differential privacy where Z denotes the noise added.\\
		\centering
		$F(x) = f(x) + Z $\\
		
		\vspace{0.25cm}
		\begin{enumerate}
			\item Provide an equation to show the relationship between $\epsilon$ (privacy budget) and $Z$? Are they directly or inversely related?
			\begin{answer}
				\[
					Z \sim Laplace\left( b \right), ~ where ~ b =\frac{\Delta}{\epsilon}
				\]
				
				Here $\Delta$ denotes the global sensitivity whereas $\epsilon$ denotes the privacy budget. $Z$ and privacy budget are inversely related.
			\end{answer}
			
			\item What does it mean to have $\epsilon = 0$?
			\begin{answer}
				$\epsilon = 0$ indicates the perfect membership privacy. That is output of a query must be exactly the same regardless of the fact that record about an individual is included or excluded in the database. This is practically not achievable and $\epsilon$ is always a trade off between privacy and the utility.
			\end{answer}
			
			\item What would be the result of adding a larger amount of noise?
			\begin{answer}
				Large noise will destroy the utilization of the data, and make it impossible to make accurate or useful decisions.
			\end{answer}
		\end{enumerate}
		
	\end{enumerate}
	
\end{document}